{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 종목별 기업 정보, 펀더멘털, 재무제표 크롤링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래 코드를 사용하려면 Selenium 패키지 다운 필요 및 FireFox 설치 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Package for Crawling\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import WebDriverException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Package for data processing\n",
    "import pandas as pd\n",
    "import re\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 종목 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#코드 불러오기\n",
    "with open('./data/kosdaq_code.txt') as f:\n",
    "    kosdaq = f.read().splitlines() \n",
    "\n",
    "with open('./data/kospi_code.txt') as f:\n",
    "    kospi = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2667 883\n"
     ]
    }
   ],
   "source": [
    "print(len(kosdaq), len(kospi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주의) kosdaq은 Daum Finance에서 여러 번 중복되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kosdaq = list(set(kosdaq))\n",
    "kospi = list(set(kospi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264 883\n"
     ]
    }
   ],
   "source": [
    "print(len(kosdaq), len(kospi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Naver에서 각 종목별 페이지 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_url = 'http://companyinfo.stock.naver.com/v1/company/c1010001.aspx?cmp_cd='\n",
    "ajax_url = 'http://companyinfo.stock.naver.com/v1/company/ajax/cF1001.aspx?cmp_cd='\n",
    "\n",
    "sheet_a = '&fin_typ=0&freq_typ=A'\n",
    "sheet_y = '&fin_typ=0&freq_typ=Y'\n",
    "sheet_q = '&fin_typ=0&freq_typ=Q'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firefox에서 제공하는 geckodriver 사용\n",
    "-> https://github.com/mozilla/geckodriver/releases 에서 자신의 운영체제에 맞는 파일 다운받으면 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path='/Users/sailyourlife/Dropbox/Project/Investment/geckodriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#데이터 처리 함수 정의\n",
    "def clean_string(string):\n",
    "    string = string.replace('\\t', '')\n",
    "    string = string.replace('\\n', '')\n",
    "    string = string.replace(' ', '')\n",
    "    string = string.replace(',', '')\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#정보 저장(kospi)\n",
    "company_info = []\n",
    "company_fundamental = []\n",
    "company_sheet_year = []\n",
    "company_sheet_quarter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sailyourlife/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/sailyourlife/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, '대한유화']\n",
      "[50, '에스원']\n",
      "[100, '한솔홈데코']\n",
      "[150, 'LG하우시스']\n",
      "[200, '부국철강']\n",
      "[250, '한국콜마']\n",
      "[300, '금호에이치티']\n",
      "[350, '제일약품']\n",
      "[400, '두산']\n",
      "[450, '흥아해운']\n",
      "[500, '이아이디']\n",
      "[550, '다우기술']\n",
      "[600, '두산밥캣']\n",
      "[650, '디아이']\n",
      "[700, '엔에스쇼핑']\n",
      "[750, '지투알']\n",
      "[800, '오뚜기']\n",
      "[850, '웅진']\n"
     ]
    }
   ],
   "source": [
    "for code in range(len(kospi)):\n",
    "    \n",
    "    #1. 기업 정보\n",
    "    sleep(0.5)\n",
    "\n",
    "    driver.get(basic_url + kospi[code])\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "        \n",
    "    #1) 이름\n",
    "    name = soup.find_all(\"span\", {\"class\": \"name\"})[0]\n",
    "    name = name.get_text()\n",
    "\n",
    "    #2) 주가\n",
    "    price = soup.find_all(\"td\", {\"class\": \"num\"})[0]\n",
    "    price = price.get_text()\n",
    "    price = clean_string(price)\n",
    "    \n",
    "    price.split('/')[0]\n",
    "    price = re.findall('\\d+', price)[0]\n",
    "        \n",
    "    #3) 52주 상한가 / 하한가\n",
    "    price52 = soup.find_all(\"td\", {\"class\": \"num\"})[1]\n",
    "    price52 = price52.get_text()\n",
    "    price52 = clean_string(price52)\n",
    "    \n",
    "    max52 = price52.split('/')[0]\n",
    "    max52 = re.findall('\\d+', max52)[0]\n",
    "    min52 = price52.split('/')[1]\n",
    "    min52 = re.findall('\\d+', min52)[0]    \n",
    "    \n",
    "    #4) 시가총액\n",
    "    total_price = soup.find_all(\"td\", {\"class\": \"num\"})[4]\n",
    "    total_price = total_price.get_text()\n",
    "    total_price = clean_string(total_price)\n",
    "    \n",
    "    total_price.split('/')[0]\n",
    "    total_price = re.findall('\\d+', total_price)[0]\n",
    "\n",
    "    #5) 수익률(1M / 3M / 6M / 1Y)\n",
    "    up_ratio = soup.find_all(\"td\", {\"class\": \"num\"})[8]\n",
    "    up_ratio = up_ratio.get_text()\n",
    "    up_ratio = clean_string(up_ratio)\n",
    "    \n",
    "    price = price.split('/')\n",
    "    price_list = [i.split('%')[0] for i in price]\n",
    "    \n",
    "    company_info.append({kospi[code]: [name, price, total_price, max52, min52, up_ratio]})\n",
    "\n",
    "    #2. 펀더멘탈\n",
    "    fundamental = soup.find_all(\"tbody\")[5]\n",
    "    fundamental = fundamental.get_text()\n",
    "    fundamental.split('\\n')\n",
    "    fundamental_list = fundamental.split('\\n')\n",
    "    fundamental_info = [elem for elem in fundamental_list if elem.strip()]\n",
    "    fundamental_info = fundamental_info[:-3]\n",
    "    \n",
    "    company_fundamental.append({kospi[code]: fundamental_info})\n",
    "    \n",
    "    \n",
    "    #3. 재무제표\n",
    "    #A. 연간\n",
    "    sleep(0.5)\n",
    "\n",
    "    driver.get(ajax_url+ kospi[code] + sheet_y)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    #1) 년월일\n",
    "    time = soup.find_all('thead')[0]\n",
    "    time = time.get_text()\n",
    "    time = time.replace('\\n', '')\n",
    "    time = time.replace('\\t', '')\n",
    "    time = re.findall('\\d+', time)\n",
    "    \n",
    "    #2) 내용\n",
    "    ybody = soup.find_all('tbody')[0]\n",
    "    ybody = ybody.get_text()\n",
    "    ybody = ybody.replace('\\n', ' ')\n",
    "    ybody = ybody.replace('\\t', ' ')\n",
    "    ybody = ybody.replace('\\xa0', '')\n",
    "    ybody_list = ybody.split(' ')\n",
    "    ybody_info = [elem for elem in ybody_list if elem.strip()]\n",
    "    \n",
    "    company_sheet_year.append({kospi[code]: ybody_info})\n",
    "    \n",
    "    \"\"\"#B. 분기\n",
    "    \n",
    "    #1) 분기\n",
    "    sleep(0.5)\n",
    "\n",
    "    driver.get(ajax_url+ kospi[code] + sheet_q)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    quarter = soup.find_all('thead')[0]\n",
    "    quarter = quarter.get_text()\n",
    "    quarter = quarter.replace('\\n', '')\n",
    "    quarter = quarter.replace('\\t', '')\n",
    "    quarter = re.findall('\\d+', quarter)\n",
    "    \n",
    "    #2) 내용\n",
    "    qbody = soup.find_all('tbody')[0]\n",
    "    qbody = qbody.get_text()\n",
    "    qbody = qbody.replace('\\n', ' ')\n",
    "    qbody = qbody.replace('\\t', ' ')\n",
    "    qbody = qbody.replace('\\xa0', '')\n",
    "    qbody_list = qbody.split(' ')\n",
    "    qbody_info = [elem for elem in qbody_list if elem.strip()]\n",
    "    \n",
    "    company_sheet_quarter.append({kospi[code]: qbody_info})\"\"\"\n",
    "    \n",
    "    if code % 50 == 0:\n",
    "        print([code, name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 빠른 저장 및 불러오기를 위해서 pickle package 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"./data/kospi_company_quarter_sheet.txt\", \"wb\") as fp:   #Pickling\\n    pickle.dump(company_sheet_quarter, fp)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#저장하기(KOSPI)\n",
    "with open(\"./data/kospi_company_info.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_info, fp)\n",
    "with open(\"./data/kospi_company_fundamental.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_fundamental, fp)\n",
    "with open(\"./data/kospi_company_year_sheet.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_sheet_year, fp)\n",
    "\"\"\"with open(\"./data/kospi_company_quarter_sheet.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_sheet_quarter, fp)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#정보 저장(kosdaq)\n",
    "company_info = []\n",
    "company_fundamental = []\n",
    "company_sheet_year = []\n",
    "company_sheet_quarter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sailyourlife/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/sailyourlife/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, '장원테크']\n",
      "[50, '코렌']\n",
      "[100, '대호피앤씨']\n",
      "[150, '바른손이앤에이']\n",
      "[200, '제이엔케이히터']\n",
      "[250, '엑시콘']\n",
      "[300, '엔터메이트']\n",
      "[350, '한프']\n",
      "[400, '리드코프']\n",
      "[450, '에이치시티']\n",
      "[500, '피에스케이']\n",
      "[550, '리더스코스메틱']\n",
      "[600, '포비스티앤씨']\n",
      "[650, '글로본']\n",
      "[700, '게임빌']\n",
      "[750, '쎄노텍']\n",
      "[800, '삼진엘앤디']\n",
      "[850, 'SK머티리얼즈']\n",
      "[900, '엠케이전자']\n",
      "[950, '부방']\n",
      "[1000, '대한과학']\n",
      "[1050, '인터파크']\n",
      "[1100, '아우딘퓨쳐스']\n",
      "[1150, '아이엠']\n",
      "[1200, '포스코켐텍']\n",
      "[1250, '인터불스']\n"
     ]
    }
   ],
   "source": [
    "for code in range(len(kosdaq)):\n",
    "     \n",
    "    #1. 기업 정보\n",
    "    sleep(0.5)\n",
    "    \n",
    "    driver.get(basic_url + kosdaq[code])\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    #1) 이름\n",
    "    name = soup.find_all(\"span\", {\"class\": \"name\"})[0]\n",
    "    name = name.get_text()\n",
    "\n",
    "    #2) 주가\n",
    "    price = soup.find_all(\"td\", {\"class\": \"num\"})[0]\n",
    "    price = price.get_text()\n",
    "    price = clean_string(price)\n",
    "    \n",
    "    price.split('/')[0]\n",
    "    price = re.findall('\\d+', price)[0]\n",
    "        \n",
    "    #3) 52주 상한가 / 하한가\n",
    "    price52 = soup.find_all(\"td\", {\"class\": \"num\"})[1]\n",
    "    price52 = price52.get_text()\n",
    "    price52 = clean_string(price52)\n",
    "    \n",
    "    max52 = price52.split('/')[0]\n",
    "    max52 = re.findall('\\d+', max52)[0]\n",
    "    min52 = price52.split('/')[1]\n",
    "    min52 = re.findall('\\d+', min52)[0]    \n",
    "    \n",
    "    #4) 시가총액\n",
    "    total_price = soup.find_all(\"td\", {\"class\": \"num\"})[4]\n",
    "    total_price = total_price.get_text()\n",
    "    total_price = clean_string(total_price)\n",
    "    \n",
    "    total_price.split('/')[0]\n",
    "    total_price = re.findall('\\d+', total_price)[0]\n",
    "\n",
    "    #5) 수익률(1M / 3M / 6M / 1Y)\n",
    "    up_ratio = soup.find_all(\"td\", {\"class\": \"num\"})[8]\n",
    "    up_ratio = up_ratio.get_text()\n",
    "    up_ratio = clean_string(up_ratio)\n",
    "    \n",
    "    price = price.split('/')\n",
    "    price_list = [i.split('%')[0] for i in price]\n",
    "    \n",
    "    company_info.append({kosdaq[code]: [name, price, total_price, max52, min52, up_ratio]})\n",
    "\n",
    "    #2. 펀더멘탈\n",
    "    fundamental = soup.find_all(\"tbody\")[5]\n",
    "    fundamental = fundamental.get_text()\n",
    "    fundamental.split('\\n')\n",
    "    fundamental_list = fundamental.split('\\n')\n",
    "    fundamental_info = [elem for elem in fundamental_list if elem.strip()]\n",
    "    fundamental_info = fundamental_info[:-3]\n",
    "    \n",
    "    company_fundamental.append({kosdaq[code]: fundamental_info})\n",
    "    \n",
    "    \n",
    "    #3. 재무제표\n",
    "    #A. 연간\n",
    "    sleep(0.5)\n",
    "\n",
    "    driver.get(ajax_url+ kosdaq[code] + sheet_y)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    #1) 년월일\n",
    "    time = soup.find_all('thead')[0]\n",
    "    time = time.get_text()\n",
    "    time = time.replace('\\n', '')\n",
    "    time = time.replace('\\t', '')\n",
    "    time = re.findall('\\d+', time)\n",
    "    \n",
    "    #2) 내용\n",
    "    ybody = soup.find_all('tbody')[0]\n",
    "    ybody = ybody.get_text()\n",
    "    ybody = ybody.replace('\\n', ' ')\n",
    "    ybody = ybody.replace('\\t', ' ')\n",
    "    ybody = ybody.replace('\\xa0', '')\n",
    "    ybody_list = ybody.split(' ')\n",
    "    ybody_info = [elem for elem in ybody_list if elem.strip()]\n",
    "    \n",
    "    company_sheet_year.append({kosdaq[code]: ybody_info})\n",
    "    \n",
    "    \"\"\"#B. 분기\n",
    "    \n",
    "    #1) 분기\n",
    "    sleep(0.5)\n",
    "\n",
    "    driver.get(ajax_url+ kosdaq[code] + sheet_q)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    quarter = soup.find_all('thead')[0]\n",
    "    quarter = quarter.get_text()\n",
    "    quarter = quarter.replace('\\n', '')\n",
    "    quarter = quarter.replace('\\t', '')\n",
    "    quarter = re.findall('\\d+', quarter)\n",
    "    \n",
    "    #2) 내용\n",
    "    qbody = soup.find_all('tbody')[0]\n",
    "    qbody = qbody.get_text()\n",
    "    qbody = qbody.replace('\\n', ' ')\n",
    "    qbody = qbody.replace('\\t', ' ')\n",
    "    qbody = qbody.replace('\\xa0', '')\n",
    "    qbody_list = qbody.split(' ')\n",
    "    qbody_info = [elem for elem in qbody_list if elem.strip()]\n",
    "    \n",
    "    company_sheet_quarter.append({kosdaq[code]: qbody_info})\"\"\"\n",
    "    \n",
    "    if code % 50 == 0:\n",
    "        print([code, name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"kosdaq_company_quarter_sheet.txt\", \"wb\") as fp:   #Pickling\\n    pickle.dump(company_sheet_quarter, fp)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#저장하기(KOSDAQ)\n",
    "with open(\"./data/kosdaq_company_info.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_info, fp)\n",
    "with open(\"./data/kosdaq_company_fundamental.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_fundamental, fp)\n",
    "with open(\"./data/kosdaq_company_year_sheet.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_sheet_year, fp)\n",
    "\"\"\"with open(\"kosdaq_company_quarter_sheet.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_sheet_quarter, fp)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kospi, Kosdaq 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"./data/kospi_company_quarter_sheet.txt\", \"rb\") as fp:   # Unpickling\\n    kospi_company_sheet_quarter = pickle.load(fp)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#읽어오기(KOSPI)\n",
    "with open(\"./data/kospi_company_info.txt\", \"rb\") as fp:   # Unpickling\n",
    "    kospi_company_info = pickle.load(fp)\n",
    "with open(\"./data/kospi_company_fundamental.txt\", \"rb\") as fp:   # Unpickling\n",
    "    kospi_company_fundamental = pickle.load(fp)\n",
    "with open(\"./data/kospi_company_year_sheet.txt\", \"rb\") as fp:   # Unpickling\n",
    "    kospi_company_sheet_year = pickle.load(fp)\n",
    "\"\"\"with open(\"./data/kospi_company_quarter_sheet.txt\", \"rb\") as fp:   # Unpickling\n",
    "    kospi_company_sheet_quarter = pickle.load(fp)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"./data/kosdaq_company_quarter_sheet.txt\", \"rb\") as fp:   # Unpickling\\n    kosdaq_company_sheet_quarter = pickle.load(fp)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#읽어오기(KOSDAQ)\n",
    "with open(\"./data/kosdaq_company_info.txt\", \"rb\") as fp:   # Unpickling\n",
    "    kosdaq_company_info = pickle.load(fp)\n",
    "with open(\"./data/kosdaq_company_fundamental.txt\", \"rb\") as fp:   # Unpickling\n",
    "    kosdaq_company_fundamental = pickle.load(fp)\n",
    "with open(\"./data/kosdaq_company_year_sheet.txt\", \"rb\") as fp:   # Unpickling\n",
    "    kosdaq_company_sheet_year = pickle.load(fp)\n",
    "\"\"\"with open(\"./data/kosdaq_company_quarter_sheet.txt\", \"rb\") as fp:   # Unpickling\n",
    "    kosdaq_company_sheet_quarter = pickle.load(fp)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 합치기\n",
    "company_info = kosdaq_company_info + kospi_company_info\n",
    "company_fundamental = kosdaq_company_fundamental + kospi_company_fundamental\n",
    "company_sheet_year = kosdaq_company_sheet_year + kospi_company_sheet_year\n",
    "\"\"\"company_sheet_quarter = kosdaq_company_sheet_quarter + kospi_company_sheet_quarter\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2147\n"
     ]
    }
   ],
   "source": [
    "print(len(company_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"company_quarter_sheet.txt\", \"wb\") as fp:   #Pickling\\n    pickle.dump(company_sheet_quarter, fp)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#저장하기(전체)\n",
    "with open(\"./data/company_info.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_info, fp)\n",
    "with open(\"./data/company_fundamental.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_fundamental, fp)\n",
    "with open(\"./data/company_year_sheet.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_sheet_year, fp)\n",
    "\"\"\"with open(\"company_quarter_sheet.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(company_sheet_quarter, fp)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"company_quarter_sheet.txt\", \"rb\") as fp:   # Unpickling\\n    company_sheet_quarter = pickle.load(fp)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#읽어오기(전체)\n",
    "with open(\"./data/company_info.txt\", \"rb\") as fp:   # Unpickling\n",
    "    company_info = pickle.load(fp)\n",
    "with open(\"./data/company_fundamental.txt\", \"rb\") as fp:   # Unpickling\n",
    "    company_fundamental = pickle.load(fp)\n",
    "with open(\"./data/company_year_sheet.txt\", \"rb\") as fp:   # Unpickling\n",
    "    company_sheet_year = pickle.load(fp)\n",
    "\"\"\"with open(\"company_quarter_sheet.txt\", \"rb\") as fp:   # Unpickling\n",
    "    company_sheet_quarter = pickle.load(fp)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2147\n"
     ]
    }
   ],
   "source": [
    "print(len(company_info))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
